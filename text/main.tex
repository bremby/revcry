
\documentclass[a4paper,10pt,openright]{memoir}

% Style of front page, title page, and stuff page
\usepackage{dikuReport}


% Packages
\usepackage[utf8]{inputenc}
\usepackage{latexsym}
\usepackage[T1]{fontenc}
\usepackage{cite}
\usepackage{pdfpages}
\usepackage{tikz}
\usepackage{fix-cm}
\usepackage{xcolor,calc}
\usepackage{graphicx}
\usepackage{amsbsy}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{alltt}
\usepackage{float}
\usepackage{color}
\usepackage{relsize}
\usepackage{calc}
\usepackage{ifthen}
\usepackage{xspace}
\usepackage{listings}
\usepackage{todonotes}
% Janus listings
\usepackage{lstjanus}

\lstset{language=C,
        basicstyle=\footnotesize\ttfamily,
        keywordstyle=\bfseries\color{blue},
        stringstyle=\color{green}\ttfamily,
        commentstyle=\color{red}\ttfamily,
        %morecomment=[l][\color{magenta}]{\#}
        columns=flexible,
        keepspaces=true
}

\lstset{language=Python,
        basicstyle=\footnotesize\ttfamily,
        keywordstyle=\bfseries\color{blue},
        stringstyle=\color{green}\ttfamily,
        commentstyle=\color{red}\ttfamily,
        %morecomment=[l][\color{magenta}]{\#}
        columns=flexible,
        keepspaces=true
}

%%%%% Make abbreviations emphasized.
\newcommand{\ie}{\emph{i.e.}\xspace}
\newcommand{\eg}{\emph{e.g.}\xspace}
\newcommand{\etc}{\emph{etc.}\xspace}
\newcommand{\vs}{\emph{vs.}\xspace}
\newcommand{\cf}{\emph{cf.}\xspace}
\newcommand{\viz}{\emph{viz.}\xspace}
\newcommand{\etal}{\emph{et~al.}\xspace}

\def\enc{\ensuremath{\mathit{enc}}}
\def\dec{\ensuremath{\mathit{dec}}}
\newcommand{\inv}[1]{\ensuremath{\mathcal{I}(#1)}}
\newcommand{\exe}[1]{\ensuremath{[\![#1]\!]}}

\newcommand{\name}[1]{\textsc{#1}}
\newcommand{\term}[1]{\textit{#1}}
\newcommand{\code}[1]{\texttt{#1}}

% Include some layout setup.
\input{layout.tex}

% Sets page numbering layout to normal
\normalPN

% Where graphic files are located
\graphicspath{{figures/}}

% Alters the margins of the pages such that text are _not_ centered. This makes better room for the glue bindings.
\addtolength{\foremargin}{-45pt}
\addtolength{\spinemargin}{45pt}
\checkandfixthelayout


\begin{document}

% Basic information
\thesistype{MSc thesis}
\thesiscomment{} % You can leave this blank
\title{Lightweight Crypto in Reverse}
\subtitle{Exploring lightweight cryptography in the context of reversible computing}
\author{Dominik Táborský}
\supervisor{Michael Kirkedal Thomsen, Ken Friis Larsen}
%\date{July 7, 2018} % Hand-in date <<<------------------------<<<-----------------<<<-----------------!!!!!! FILL IN !!!!<<<-------------
%\subject{The short description that is suitable for a database.} % This is not needed.

% Make the front page, title page, and other required information.
\pagestyle{plain}
\maketitle

% Start at page 3. I do not count the front page in the numbering.
\cleardoublepage
\pagenumbering{roman}
\setcounter{page}{3}

% English Abstract
\cleardoublepage
\pagestyle{plain}
\begin{abstract}
Abstract
\end{abstract}

% Danish abstract
% \clearpage
% \begin{resume}
% Dansk resum\'e
% \end{resume}

% Table of contents
\cleardoublepage
\chapterstyle{combined}
\tableofcontents*


% Starting the real text.
\cleardoublepage
\pagenumbering{arabic}
\setcounter{page}{1}


%%\cftaddnumtitleline{toc}{chapter}{Preface}{}{}%
%\cftaddnumtitleline{toc}{chapter}{Preface}{}{\arabic{page}}%
%\chapter*{Preface}

%Preface and acknowledgements if you like to have this.



\cleardoublepage
%%\cftaddnumtitleline{toc}{chapter}{Preface}{}{}%
%\cftaddnumtitleline{toc}{chapter}{List of Abbreviations}{}{\arabic{page}}%
%\chapter*{List of Abbreviations}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% INTRODUCTION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\cleardoublepage

\chapter{Introduction}

%Overview of the context, current problems and difficulties, discussion 
%of current solutions, our solution and its short evaluation.

Cryptography has been with us for decades now, yet only 
recently we figured out how to reliably code and verify an 
actual implementation with the F*/HACL work \cite{ProtzenkoEtal:2017}. 
A similar approach takes the Vale project \cite{BondEtal:2017:Vale}, 
designing a new language that utilizes either Dafny or F* for 
verification. These solutions verify not only the correctness of the 
code, but also prove the lack of state-based information leakage, and 
in the case of Vale, even timing-based leakage. These two are possibly 
the easiest side-channel vulnerabilities to exploit, especially given 
the fact that physical access to the computer is not necessary. Both of 
them can get difficult to control for since the compiler often provides 
no guarantees on the generated machine code. Similarly, general high-level programming 
languages do not provide semantics on low enough level to account for 
registers, caches and execution timing. Vale provides for these, which 
allows it to formally verify the required cryptographic properties.

Our work aims for exploiting reversible computing to reason about 
state-based leakage. Informally, a reversible program has to follow a 
clearly defined path that transforms the input data to output data 
without losing information. Because of that lack of information loss, 
it can be described as an injective function. Encryption algorithms are 
bijective functions, implying they can be directly encoded in a 
reversible setting. In a formal description, we have

$$
\exe{\enc}(k,p) = (k,c) \,.
$$

The plaintext $p$ is directly transformed to a ciphertext $c$, while 
key $k$ remains the same. Note that the key cannot be omitted: either 
such the function would not be injective, thus irreversible, or the 
ciphertext would somehow contain the key, which would make the 
encryption useless by making the key public. 

In Janus we enforce this scheme by offloading any other data (\eg algorithm-specific magic constants or iterators) into 
temporary local variables. These variables are declared and defined at 
the top of a function and undeclared at the bottom, with their final 
value specified. This final value is necessary for reversibility: 
without it, such reversed function would have undefined initial values. 
Secondly, because we know the final value of each variable, that value 
can be subtracted from the variable, thus clearing it. This implies 
that local data, not part of the input and output, will be cleared and 
thus no state-based leakage is possible. We demonstrate this by 
translating a Janus program to C and executing it within a virtual 
environment that tracks secret data (see chapter \ref{sec:eval}).

Furthermore, thanks to reversibility we implement only the encryption 
functions. The decryption is then obtained by reversing the encryption. 
This decreases time spent on development, debugging, testing and 
showing the duality of encryption and decryption functions.

Our conclusion is that reversibility is a handy tool for developing not 
only cryptographic code, but also other injective functions. It gives 
no guarantees on avoiding timing vulnerabilities like Vale does, 
however it comes at a much lower cost of development. We also take note 
of the difficulty to learn and use Vale due to the sheer breadth of 
details the programmer has to consider, instead of leaving it to the 
compiler.





%The reason for 
%vulnerabilities based on the implementation and not the mathematical 
%basis of the algorithm is usually performance, simplicity, inexperience 
%and even language and/or compiler support for low-level semantics.




\section{Goals}
\label{sec:goals}

Our aim is to explore the combination of reversibility and 
cryptography. Irreversible implementations of crypto algorithms often 
either suffer from insufficiencies from the security perspective or are 
difficult to implement correctly. Due to performance being also 
critical, programmers have to actively fight compilers to make sure 
their code is safe. Our main goal is to alleviate that in at least some 
way. Reversible code is limited in how it manages memory - no erasure 
is allowed, and so deallocations have to be preceded by proper 
cleanup. Reversible algorithms can follow a much cleaner formal 
definition that does not leak memory contents outside the scope of 
those functions.

The second goal is to exploit the bijectivity of crypto algorithms. 
Decryption is just an inverse function to encryption, so only one of them 
needs coding. This lowers the implementation and debugging time demands.

The third goal is getting some practical experience with Janus, finding 
its strenghts and weaknesses and suggesting improvements.

\section{Problem statement}

Classic irreversible implementations of encryption schemes suffer from 
human errors making them vulnerable to side-channel exploits. 
Reversible implementation removes one type of side-channel and has 
potential to alleviate the cost of development and debugging.

\section{Overview of the chapters}

Apart from the Introduction, these are the chapters and their short 
summaries this thesis builds upon:

\begin{description}

\item[Analysis] Presents short introduction to cryptography, discusses 
the practical problems with side-channel vulnerabilities, and explores 
reversible computing and its implications in the context of 
cryptography.

\item[Design] Talks about how we approach the problem with a selection 
of algorithms, their expected behaviour and how we can verify a lack of 
state leakage.

\item[Implementation] This chapter focuses on writing the selected 
algorithms in Janus and the practical experience of it.

\item[Evaluation] Here we discuss how we verify our claims, then 
suggest and perform some experiments to do that. We also look at how we 
can work around the problem of not having a fully reversible platform. \todo{do the last sentence}

\item[Reflection and future work] We reflect on how well our solution 
can work in practice, and what else needs to or should be done. \todo{do so}

\end{description}

\chapter{Analysis}

%In this chapter we look at lightweightedness in cryptography, consider 
%fundamental properties of reversibility, analyze properties of our 
%solution{ and define terminology}.

\section{Symmetric and asymmetric cryptography}

Cryptographic algorithms can be defined as functions that take two 
parameters, a key and some data, perform either encryption or 
decryption and return the key and the modified data. Normally the key 
in the result would be omitted, however it is useful to recognize the 
fact that the key is not altered in any way. This will become useful 
later on.

Symmetric cryptography differs from the asymmetric kind by its use of 
only a single key for both encryption and decryption. These are the 
classic algorithms like AES, RC5 and Chacha20. They also tend to be 
much more efficient performance-wise than their asymmetric siblings. 
This efficiency also lead to establishing the subarea of 
\term{lightweight cryptography}. Algorithms classified as 
\term{lightweight} are generally good candidates for use in 
\term{Internet of Things (IoT)} devices, which often have low 
computational performance, need to limit power usage, have strict 
memory requirements, or even may be required to react quickly. A 
special kind of symmetric cryptographic algorithms are stream ciphers, 
which only generate seemingly random output which is then combined with 
the input data (plaintext or ciphertext) using some self-inverting 
operation, typically XOR. Therefore stream ciphers only implement this 
"random" output and not individual encryption and decryption functions, 
since they are trivial and equivalent.

Asymmetric cryptography, also known as \term{Public Key Cryptography 
(PKI)}, uses one key for encryption (a \term{public key}) and another 
for decryption (a \term{private key}). Its security relies on some hard 
mathematical problems like integer factorization in the case of RSA. If 
that could somehow be performed as fast as the factor multiplication, 
it would render the whole algorithm broken. It does not achieve the 
same levels of performance \cite{sym-asym} and for that reason it is not 
considered lightweight. It can, however, be used for so-called hybrid 
encryption schemes, where PKI is used to exchange the secret key for 
some symmetric algorithm.

\subsection{Definition}

Formally we use the following notation to describe a function 
$\enc_S$ and its inverse $\dec_S$ that fits the description above:

\begin{align*}
\enc_S(k,p) = (k,c) \\
\dec_S(k,c) = (k,p) 
\end{align*}

This suffices to describe symmetric cryptographic algorithms including 
stream ciphers where $\enc = \dec$.

For asymmetric algorithms we have to differentiate between public and 
private keys:

\begin{align*}
\enc_A(k_\text{public},p) = (k_\text{public},c) \\
\dec_A(k_\text{private},c) = (k_\text{private},p) 
\end{align*}

However, notice one major difference between the encryption functions 
$\enc_S$ and $\enc_A$: the resulting pair $(k, c)$ of $\enc_S$ contains 
all necessary information to decrypt the ciphertext back using 
$\dec_S$. That is not the case with $\enc_A$: having access to 
$(k_\text{public},c)$ does not suffice for decryption, since we are 
missing the private key $k_\text{private}$. This is an important 
distinction that we will explore later in \ref{sec:asym_rev}. In short, 
the implication is that the definition of $\enc_A$ is not as complete 
as $\enc_S$.

\section{Vulnerabilities in cryptographic code}

The mathematical basis upon which cryptographic algorithms are built is 
only one half of the story when it comes to evaluating data security. 
The other half are their implementations, which have a long history of 
hidden vulnerabilities in various forms. These are often split into two 
groups\footnote{A word on the classification: the grouping provided 
here follows other sources. From a second perspective, state-based 
leakages can also be considered a side-channel, since the mathematical 
concept of cryptography does not deal with how memory is handled. We 
can counter such argument by saying that the state, especially the key 
and the plaintext, should remain secret no matter the code. 
Nevertheless, the classification is only secondary for our 
purposes.}:incorrect implementation (software bugs, state-based 
leakages) and so-called \term{side-channel vulnerabilities}, 
\term{side-channel information leakages} or just \term{side-channels} 
for short. The first group consists of attacks on weaknesses in the 
software implementation, mostly state information leakage via registers 
and/or memory, \ie not clearing memory containing sensitive data 
\cite{Chow:2004}. The second group is classified into several subgroups 
depending on the type of the attack, \eg power consumption and 
electromagnetic radiation analyses \cite{Spreitzer:2016}. A 
timing-based attack exploits different running times of the algorithm 
depending on its inputs. Arguably, this kind of attack could be 
classified as both a software bug, since it can be often circumvented 
in code, but the source of the problem often lies within the processor 
itself (instructions themselves being timing-sensitive based on input 
\cite{TimingRC5}).

The easiest (in terms of required prerequisites) are state-based and 
timing-based leakages, since they can be performed remotely and do not 
require any specialized hardware. Because of that, they tend to be the 
focus of contemporary research in the area 
\cite{BondEtal:2017:Vale}\cite{whatyouc:2018}.

\subsection{Examples}

The common issue with state-based information leakage is that either 
the programmer does not clear the memory that contains the sensitive 
data (\eg a password) and simply deallocates it, or that they do clear 
it in the code, but the compiler removes that code because it is 
considered a dead (ineffective) code.

\begin{lstlisting}
int login()
{
  int ret = 0;
  char *password = ask_for_password();
  //ret = ... use the password
  memset(password, 0, strlen(password));
  return ret;
}
\end{lstlisting}

In the above example, the memory pointed to by the \code{password} 
variable is supposed to be cleared out using the \code{memset} 
function, but since the memory is not being used anymore, optimizing 
compilers remove that call completely\cite{whatyouc:2018}.

An example of a timing vulnerability is in the case of the RC5 
algorithm \cite{TimingRC5}, which uses bitwise rotation, where the 
number of bits rotated depends on the input data. The vulnerability 
exists only on some platforms, which differ from the others in the 
implementation of the rotation instruction. The rotation can be 
performed in two ways: 
\begin{enumerate}
\item perform one rotation by $n$ bits,
\item perform $n$ rotations by 1 bit.
\end{enumerate}
This minor change can have drastic effects on security.

\subsection{Avoidance}

There are multiple ways for avoiding side-channel vulnerabilities, but 
most (if not all) of them require some extra work on the programmer's 
side. The most time consuming and also error-prone method for avoiding 
state leakage would be manually clearing memory. Just tracking the used 
memory would be exhausting. Naturally, the programmer could create a 
\term{memory pool}, \ie a block of memory, where the algorithm would 
store its data. This block would then be erased altogether after the 
algorithm has finished. Along with that, the programmer would also need 
to erase the stack and processor registers. A reliable way of doing 
that is extending a compiler, which is described in \cite{whatyouc} and 
which we also use (see section \ref{sec:verifmet} and later 
\ref{sec:eval}).

Avoiding a timing side-channel is significantly harder, since it 
depends on the processor instruction semantics and may depend on the 
algorithm. There has been some progress with this, and we discuss this 
in \ref{sec:verifmet}. Every side-channel is specific, however, and 
requires specific countermeasures. In case of the power analysis, for 
example, the actual device has to be designed from the ground up to be 
resilient.



\section{Reversibility and its implications}

Reversibility is the ability of a program to be executed both forwards 
and backwards deterministically. Although discussed earlier, first 
major research was done by Landauer\cite{Landauer61}. 
Bennett\cite{Bennett73} and others continued the research and a first 
logically reversible language Janus was born (\cite{janus86}, 
\cite{Yokoyama2010}).

\subsection{Definitions}

Consider a reversible program $p$ and some values $x$ and $y$. Then 
$\exe{p}(x) = (y)$ represents\footnote{Here we are using the notation 
from \cite{Jones93}.} the execution of program $p$ with $x$ as a given 
parameter and $y$ being the result. So in the case of encryption we 
have:

$$
\exe{\enc}(k,p) = (k,c) \,.
$$

Note that before $\enc$ represented a function in a mathematical sense, 
but in this case it is a program composed of some instructions. The 
$\exe{\cdot}$ operator stands for the forward interpretation of the 
given program. For backward interpretation we use the inversion 
operator $\inv{\cdot}$, which takes a program and inverts it, so that 
$\exe{\inv{\cdot}}$ runs the given program backwards. Now we clearly 
get that:

$$
\exe{\inv{p}}(\exe{p}(x)) = x \,.
$$


\subsection{Cryptography as a reversible embedding}
\label{crypto-embed}

Some cryptographic functions are partial functions, but we can always 
limit their domains to valid inputs. We will also assume these 
functions are injective. Altogether, we can assume to work with 
bijective functions. With this assumption, we can already make one 
interesting observation:

\begin{align*}
\exe{\enc}(k,p) &= (k,c) \\
\exe{\dec}(k,c) &= \exe{\inv{\enc}}(k,c) = (k,p) \,.
\end{align*}

The implication of that is that we can avoid implementing the 
decryption functions after having implemented the encryption ones (and 
vice-versa). In practical experience, this fact is easily observable 
and immensely useful. It has several advantages:

\begin{enumerate}
\item time saved on implementing the inverse function,
\item time saved on debugging it and making sure it actually is the correct inverse
\item easier maintenance and changes
\item smaller source files (and potentially even binary files)
\end{enumerate}

We can see examples in the code developed alongside this thesis; no 
algorithm required separate encryption/decryption functions.

\subsection{Expressive power}
\label{sec:expr-power}

Bennett has formalized \cite{Bennett73} a reversible Turing machine 
using deterministic and reversible operations. Quite clearly the 
expressive power of the reversible Turing machine is not larger than of 
the irreversible one; irreversibility allows for information erasure, 
it does not require it. Similarly, the power is not smaller. This can 
be shown by having the irreversible machine keep a log of its 
operations and intermediate values, run its algorithm to finish to 
compute the output, copy the output (without logging) and then run all 
its operations backwards using the log. The complete proof was also 
shown by Bennett \cite{Bennett73}. Below is a simple example for 
addition:

\begin{lstlisting}[language=c]
  state: x = 3, y = 5, z = 0, output = 0  // initial state
  log: empty
  z = (x + y)                             // original algorithm
  state: x = 3, y = 5, z = 8, output = 0  // forward run finished
  log: set z to (x + y), was 0
  output = z                              // copy result to a safe location, log ignored
  state: x = 3, y = 5, z = 8, output = 8  // copy saved
  log: set z to (x + y), was 0
  z = 0                                   // run original algorithm backwards
  state: x = 3, y = 5, z = 0, output = 8  // final state with initial input values, 
                                          // correct result and no intermediate values
  log: empty
\end{lstlisting}




\subsection{Reversing asymmetric cryptography}
\label{sec:asym_rev}

When we formally defined functions $\enc_S$ and $\enc_A$, we noticed 
the distinction in what information they give as a result. After 
looking at reversibility and seeing what it provides for symmetric 
cryptography, naturally it may seem like reversibility breaks 
asymmetric cryptography since an attacker knows both values, the public 
key and the ciphertext. We also know that reversibility does not 
increase expressive power of a language, it is just as powerful as a 
general Turing machine. So where is the problem?

The problem is that our definition was not complete. If the pair of the 
public key and the ciphertext contained all the information, then the 
algorithm would not provide any security. The security is exactly in 
the fact that the attacker has to search for some hidden information 
that is not available to them. One way of looking at this is simply 
considering multiplication: multiplying 3 and 4 has only one result, 
but if we know the result is 12, we do not know what the factors were. 
If we knew one of them was 3, then we would have all the information 
and could just calculate the other one. With irreversible setting this 
is not a problem, we delete information all the time, but that is not 
an option with reversible languages.

The correct and complete definition of $\enc_A$ would then be:

\begin{align*}
\enc_A(k_\text{public},p) = (k_\text{public}, p, c) \\
\end{align*}

Of course the plaintext is not transmitted or shared, only the 
ciphertext is. This definition avoids information loss and can be 
directly reversed by simply uncalculating\footnote{By "uncalculating" 
we mean reversing the program execution, thus going from the output 
back to the input. See also Bennett's tricks later in this chapter.} 
the ciphertext. In the case of the RSA algorithm, the public key has 
two components which are combined with the plaintext input in a 
loss-ful way. How this operation works is well-understood, out-of-scope 
of this thesis and the details are not important for us here.

\subsection{Data transformation}

Going back to section \ref{crypto-embed}, the second mentioned 
advantage of the duality of encryption and decryption functions, and 
similarly with other bijective functions that can be reversed like 
this, should not be underestimated. The world of programming languages 
is constantly trying to improve to make the job easier for programmers. 
Just like some languages are more useful (or at least more common) in 
certain fields (\eg C for low-level systems, Haskell for parsing, pure 
computer science and language development, C++ for performance-hungry 
video games and Java for enterprise applications), reversible languages 
could create a new such field. Algorithms that perform some kind of 
data transformation - mathematically bijective or at least injective 
function application - would be a good fit. The reversibility would 
then assist with error recovery, for example; it could prove useful in 
transactional systems, which require the ability to roll back aborted 
transactions.

\subsection{Bennett's tricks}

In section \ref{sec:expr-power} we have already seen the first trick 
for converting irreversible programs into reversible ones. The trick is 
fairly simple: to get a result of any function that may create and 
destroy any number of bits of information, simply provide temporary 
storage for those bits, run the function without erasing anything until 
completion, copy out the result and finally run the function backwards, 
uncomputing the temporary values in the process. This trick was used 
several times in the cryptographic code developed for this thesis. The 
\term{Speck} algorithm is a good example of that, as it requires to 
perform a fairly complicated key expansion process. There are a few 
other places where this trick was used, but always only in cases where 
making a more direct reversible code - that would be equivalent to the 
originally intended meaning - was either impossible or too difficult.

There also exists a second trick that is not immediately obvious. Having 
a reversible program $p$ and some input $x$ and corresponding output $y$, the 
following holds:

\begin{align*}
\exe{p}(x) = y
\exe{\inv{p}}(y) = x
\end{align*}

This is just the definition of reversibility. However, the trick is in 
how this is used: suppose the reversible program $p$ computes its input 
into output without loss of information. We can store $x$ and $y$ at 
different memory locations, so that the information within $x$ is 
duplicated in $y$. If $x$ is not needed anymore, we can uncompute it by 
executing the inverse of $p$ with $y$ as its input and $x$ as its 
output. This method is also described in \cite{Bennett73}.

\begin{align*}
&\text{state: } a = 3, b = 0, p(x,y) = \lambda x. \lambda y. y += (x + 5)\\
&\exe{p}(a,b)\\
&\text{state: } a = 3, b = 8, \inv{p}(x,y) = \lambda x. \lambda y. y -= (x - 5)\\
&\exe{\inv{p}}(y,x)\\
&\text{state: } a = 0, b = 8\\
\end{align*}

%\begin{lstlisting}[language=c]
  %state: x = 3, y = 0, f(x) = x + 5 // initial state
  %y += (x + 5) f(x)    // original algorithm
  %state: x = 3, y = 8, // forward run finished
  %state: x = 3, y = 5, // copy saved
  %x -= f^-1(y)         // run original algorithm backwards
  %state: x = 3, y = 5, output = 0, output_copy = 8  // final state with initial input values, the correct result and no intermediate values (empty log)
%\end{lstlisting}

This second trick was used only in the Salsa20 algorithm in the 
\code{quarterround} procedure. 

\subsection{Reversible languages}

There have been several reversible languages designed (a short summary 
is provided at the end of \cite{Yokoyama2010}), but so far \term{Janus} 
has proven most useful. It has an actively developed interpreter in 
Haskell, another interpreter in JavaScript, which enables running code 
in a web browser and it was also extended several times 
\cite{janus}. Janus is a (semi-)high-level C-like language, which 
makes it a fit for comparing implementations with actual C code. Author 
also has to acknowledge the fact that one of the supervisors is the 
developer of the interpreter in Haskell, and our cooperation has 
brought many patches, updates and extensions to it.

Another language that has been considered for this work was RFun, a 
reversible functional language. However, at the time of writing, RFun 
was very limited in its abilities, especially when dealing with 
numbers. Cryptographical code almost always uses some form of bitwise 
operations and those are not available under Peano number arithmetics; 
secondly, most of such code is also imperative, not functional. 
Furthermore, a new development of this language was just under way, so 
it made sense to stick to a more stable and workable tool.

%\section{Terminology}

%directly reversible = an injective function -- wtf??? so how's Bennett's trick related to that?


\chapter{Design}

%This chapter defines the inputs and outputs for crypto algorithms, 
%expected behaviour and goals and finally methods of evaluating those 
%properties. 

\section{Avoiding state information leakage}

Clearly, reversible code cannot delete information since the output 
would not be reversible back into its corresponding input. Similarly, 
no information can be "created", since that would be information 
deletion when reversed. Information can be duplicated and 
de-duplicated; one is the inverse of the other, so it is consistent 
with reversibility. In theory, we can apply this in our bijective 
crypto algorithms so that for every bit of input information, we output 
exactly one bit of output information. So assuming the key and 
plaintext memory locations are taken care of properly with regards to 
security, then any implementation can avoid leaking information by 
using only these safe memory locations and uncalculating anything else.

\section{Example algorithms}

Let us select some algorithms to work with. We will start with one of 
the simplest and still practical encryption algorithms, then move on to 
some more well known.

Note that these algorithms fit in the \textbf{ARX} group as they are 
based on three operations: \textbf{A}ddition, \textbf{R}otation and 
\textbf{X}OR operation. This makes them somewhat similar, but they are 
still different enough to validate our choices; from very simple to 
complex, block and stream ciphers, old and new. The advantage is that 
all these three operations are trivially reversible.

\subsection{TEA}

The \term{Tiny Encryption Algorithm} (TEA)\cite{tea95} is, per its 
name, incredibly simple and small. It is so simple that we can even 
show the complete code for it here; however, since decryption is just a 
reversal of encryption, we are showing only the encryption procedure:

\begin{lstlisting}[language=C]
void encrypt (uint32_t* v, uint32_t* k) {
    uint32_t v0=v[0], v1=v[1], sum=0, i;           /* set up */
    uint32_t delta=0x9e3779b9;                     /* a key schedule constant */
    uint32_t k0=k[0], k1=k[1], k2=k[2], k3=k[3];   /* cache key */
    for (i=0; i < 32; i++) {                       /* basic cycle start */
        sum += delta;
        v0 += ((v1<<4) + k0) ^ (v1 + sum) ^ ((v1>>5) + k1);
        v1 += ((v0<<4) + k2) ^ (v0 + sum) ^ ((v0>>5) + k3);
    }                                              /* end cycle */
    v[0]=v0; v[1]=v1;
}
\end{lstlisting}
\textit{\footnotesize Source: Wikipedia}\\

The decryption procedure is analogous. Both procedures take two 
arguments, a key and some data, and perform the necessary operations; 
if we avoided using the local variables \code{v0}, \code{v1}, \code{k0} 
and \code{k1} and replaced them by what they actually refer to, \ie 
\code{v[0]}, \code{v[1]}, \code{k[0]} and \code{k[1]}, the changes 
would be performed in-place, thus avoiding spilling any secrets 
anywhere else in memory, except for processor registers.

There are two subsequent extensions, named \term{XTEA} and 
\term{XXTEA}, which improve the cryptographic security. XTEA performes 
slightly different updates of those \code{v*} variables, but is the 
same otherwise. XXTEA finally encrypts a whole block of data instead of 
just two words. It also uses a few more local variables, but the 
general approach is identical. We discuss XXTEA in more detail in 
section \ref{sec:impl:tea}.

\subsection{RC5}

A somewhat more complicated algorithm is \term{RC5}, which was a 
candidate for the \term{AES}. Unlike TEA, RC5 already performs 
something called \term{key expansion}. Key expansion often extends the 
key to a larger data stream; in the case of RC5, the number of 
encryption rounds is the defining factor in that length. Additionally, 
some further mathematical operations are applied to it, increasing 
randomization of key bit distribution. This expansion is performed once 
for a single key and then re-used, since it only depends on the key and 
some predefined constants. The encryption itself can then be much 
simpler, as is the case here. Let us look at RC5 more closely:

\begin{lstlisting}[language=C]
void RC5_ENCRYPT(uint32_t *v, uint32_t *S, int rounds)
{
   uint32_t i, A = v[0] + S[0], B = v[1] + S[1];
   
   for(i = 1; i <= r; i++)
   {
      A = ROTL(A ^ B, B) + S[2*i];
      B = ROTL(B ^ A, A) + S[2*i + 1];
   }
   v[0] = A; v[1] = B;
}
\end{lstlisting}
\textit{\footnotesize Sources: Wikipedia, RC5 paper}\\

Just like with TEA, the encryption can be performed in-place. Unlike 
TEA, the procedure technically asks for a third parameter, a number of 
rounds; of course that can be removed by using a fixed constant. Also 
note that the \code{S} variable represents the expanded key, which 
brings us to the expansion itself, which is finally interesting 
(presenting it in a pseudocode for clarity):

\begin{lstlisting}[language=Python]
# w - The length of a word in bits, typically 16, 32 or 64.
# u - The length of a word in bytes.
# b - The length of the key in bytes.
# K[] - The key, considered as an array of bytes (using 0-based indexing).
# c - The length of the key in words (or 1, if b = 0).
# L[] - A temporary working array used during key scheduling. initialized to the key in words.
# r - The number of rounds to use when encrypting data.
# t = 2(r+1) - the number of round subkeys required.
# S[] - The round subkey words.

# Break K into words
u = w / 8
c = ceiling( max(b, 1) / u )
# L is initially a c-length list of 0-valued w-length words
for i = b-1 down to 0 do:
    L[i/u] = (L[i/u] << 8) + K[i]
     
# Initialize key-independent pseudorandom S array
# S is initially a t=2(r+1) length list of undefined w-length words
S[0] = P_w
for i = 1 to t-1 do:
    S[i] = S[i-1] + Q_w
    
# The main key scheduling loop
i = j = 0
A = B = 0
do 3 * max(t, c) times:
    A = S[i] = (S[i] + A + B) <<< 3
    B = L[j] = (L[j] + A + B) <<< (A + B)
    i = (i + 1) % t
    j = (j + 1) % c

# return S
\end{lstlisting}
\textit{\footnotesize Source: Wikipedia}\\

The first loop only makes sure the key is represented in little-endian 
form. The second loop is just an initialization of the buffer 
containing the expanded key. The important randomization occurs in the 
last loop, which seems slightly complicated at first glance. The 
iteration itself does not use a single variable, but instead uses both 
\code{i} and \code{j}, since both are used as an index for different 
arrays that may have different lengths. Furthermore, the number of 
loops is also not set by a single value - it is selected as a maximum 
of two values. And last but not least, the \code{A} and \code{B} 
variables are being re-set on every loop. No wonder that when we look 
at the paper establishing RC5, we find this note: 

\textit{,,The key-expansion function has a certain amount of 
``one-wayness'': it is not so easy to determine K from S.''}

For our purpose, which is re-writing the procedure in a reversible 
language, that does not sound encouraging. On the other hand, we know that 
we can make anything reversible using a Bennett's trick at worst. The 
solution is simple: these statements are actually not 
mutually-exclusive: the fact is that S is not the only result of the 
expansion function, because both S and L get updated so that they are 
dependent on each other. So it is true that getting K from S is not 
easy, but it is easy to get K from both S and L.

\subsection{Salsa20 and Chacha20}

Salsa20 and Chacha20 are relatively new algorithms. Unlike previous 
algorithms, they are \term{stream ciphers}, meaning they do not take 
the plaintext as an argument, but they generate a stream of random 
bits, which is then combined (\eg using XOR) with the plaintext. 
Chacha20 is based on Salsa20 and has improved both performance and 
security. Code complexity is comparable to RC5, but it is more synoptic 
with Chacha20 being even more so than Salsa20 - this becomes clear when 
reading the Janus code.

Interestingly, both documents for Salsa20 and Chacha20 mention 
invertibility unlike other documents. Invertibility referred to the 
mathematical property of bijectivity rather than reversibility as in 
our case. Even though invertibility is explicitly mentioned (and 
required), the code is not reversible directly, as they require some 
manipulation through a temporary local variable. That is caused by the 
lack of proper feature of the Janus language rather than some deeper 
reason. Details, including a suggestion for improvement of Janus, are 
discussed in section \ref{sec:impl:salsa}.

\subsection{Simon and Speck}

Finally we discuss two ciphers designed by NSA, the American 
intelligence agency. We wanted to see whether reversibility has any 
potential to reveal crypto algorithm weaknesses. Nothing specific was 
discovered except a general sense of difficulty implementing them. 
Although Simon is simpler than its companion, Speck contains multiple 
uses of Bennett's tricks due to complications with reversing some of 
the calculations. Even when compared to Salsa20 and Chacha20, which 
both have more lines of code than Speck, both were easier to write. 
That experience may be explained with more precise documentation. The 
fact that both Salsa20 and Chacha20 contain fewer and \textit{,,less 
weird''}~\footnote{From purely personal experience. I cannot offer 
formal quantification.} occurrences of Bennett's tricks, however, 
cannot.

\begin{lstlisting}
\end{lstlisting}


\section{Defining inputs, outputs and expected behaviour}

Thanks to assumed bijectivity, we can define two inputs and two outputs for each of our algorithms. \todo{even RC5?}
\todo{ Also stream ciphers, watch out}

\section{Verification methods}

To verify whether our code fits our formal expectations, we have 
several options to choose from. We will split them into two groups 
based on user involvement and discuss these separately.

\subsection{Manual methods}

Among the simplest, most demanding and least dependable is experimental 
behaviour observation and/or testing. We will experimentally show our 
code cleans up memory after usage.

The second way is showing that cleanup processing using a debugger. 
That way we can directly point to location in the code where that 
cleanup occurs. We will use \term{gdb} to demonstrate memory getting 
zeroed out.

The third way is manually analysing the actual generated machine code. 
We will isolate and analyse the instructions related to memory cleanup.

\subsection{Automatic methods}
\label{sec:verifmet}

There are some ways to verify different properties automatically; or to 
enforce them. Methods like theorem provers, however, tend to be 
difficult to employ. They often require non-trivial amount of skilled 
work just to formally prove correctness can be as high or even higher 
than implementing the algorithm in the first place. \todo{citation 
needed} We will not be using this method.

On a related note, there has been some research made into and 
real-world application of language-based safe code recently: notably, 
\term{F*} and its derivative \term{Low*} \cite{Low*}, and the related 
language \term{Vale}\cite{vale2017}. Low* has been used in the 
\term{HACL} project, which has been integrated into Mozilla Firefox as 
a crypto library. Vale is a language dedicated to writing verifiable 
low-level code; its authors also implemented some crypto algorithms, 
successfully verified their resistance to state-based and timing-based 
information leakage and even showed some performance gains. Vale has a 
huge potential, but at the time of writing it also lacks stability, 
documentation, examples and manuals. Only an unsuccessful attempt to 
use Vale was made. Details will be discussed later. \todo{discuss later}

Another approach is turning the compiler into an ally rather an 
obstacle that has to be worked-around. Such approach was taken by the 
authors in a very recent paper\cite{whatyouc}. They have implemented an 
extension to the LLVM/Clang compiler that adds the ability clearing out 
registers and stack, and to make a selection between two values in 
constant time. The C11 standard also added \code{memset\_s}, which the 
compiler is supposed to guarantee to never remove and so it can be used 
for clearing out heap memory. We will be using this method in 
combination with the manual methods to verify results.

Lastly, there are projects that offer tracking of sensitive data (or 
rather taints\todo{taints? is this even the right word?}) when moved 
around in memory. These are \term{taintgrind} and its derivative 
\term{secretgrind}, with the latter being specifically designed for 
crypto algorithms. We will be using secretgrind to track tainted data. 
This will be in combination with the register and stack clearing 
method, described above, to make sure nothing of the secret computation 
is preserved.



\chapter{Implementation}

In this chapter we show our Janus code for the selected algorithms and 
discuss it. We talk about the conversion from irreversible to 
reversible and even come up with improvements to Jana, the Janus 
interpreter.


\section{Algorithms}

\subsection{TEA}
\label{sec:impl:tea}

TEA translates to Janus almost directly like in any language, only the 
local variable allocation and deallocation is Janus-specific.

\begin{lstlisting}[language=Janus]
procedure TEA_encipher(u32 data[], u32 key[])
    local u32 delta = 2654435769
    local u32 sum = 0
    iterate int i = 1 by 1 to 32
        sum += delta
        data[0] += ((data[1] * 16) + key[0]) ^ (data[1] + sum) ^ ((data[1] / 32) + key[1])
        data[1] += ((data[0] * 16) + key[2]) ^ (data[0] + sum) ^ ((data[0] / 32) + key[3])
    end
    delocal u32 sum = 32*delta
    delocal u32 delta = 2654435769
\end{lstlisting}

XTEA is just as easy to translate. With XXTEA, we need to carefully 
update some local variables. Let us look at the code, starting with C:

\begin{lstlisting}
#define MX ((z>>5^y<<2) + (y>>3^z<<4) ^ (sum^y) + (k[p&3^e]^z))

long xxtea(unsigned long* v, unsigned long n, long* k) {
  unsigned long z = v[n-1], y = v[0], sum = 0, e, delta = 0x9e3779b9;
  long p, q;
  q = 6 + 52/n;
  while (q-- > 0) {
    sum += delta;
    e = (sum >> 2) & 3;
    for (p=0; p<n-1; p++) {
      y = v[p+1];
      z = v[p] += MX;
    }
    y = v[0];
    z = v[n-1] += MX;
  }
  return 0;
}
\end{lstlisting}
\textit{\footnotesize Source: Wikipedia, edited}\\

Note that the code is readable thanks to the MX macro, which is not 
available with Janus\footnote{We could use some preprocessor like 
\term{m4} or \term{cpp} like C does, but the Janus interpreter would 
not translate that into C without recognizing (or ignoring) it 
itself. It is, therefore, a good suggestion for Jana improvement.}.

The problematic parts are the \code{e}, \code{y} and \code{z} 
variables. They are being reset repeatedly, erasing information. 
Furthermore, \code{z} is being set to a value that is dependent on 
itself and that is not allowed in Janus. Since \code{e} is set to 
values dependent only on the variable \code{sum}, which is altered only 
at the beginning of the main loop, and then some constants, we know we 
can recalculate \code{e} at the end of the loop again. So to update 
\code{e} reversibly, we simply subtract the same value it has at the 
end of the loop.

The problem with \code{y} and \code{z} is their dependency on each 
other\footnote{This dependency is eventual with \code{y} and immediate 
with \code{z}.}. The easy way to overcome this is to use a Bennett's 
trick. The harder way is figuring out what is actually being updated 
and with what values. In the case of XXTEA this is still fairly 
manageable, so let us practice. The first thing we realize is that we 
can safely replace \code{y} with whatever data it was set to. We see 
that it is being set to the value of \code{v[p+1]}, so we replace all 
occurrences of y with that. Along with that we also have to partially 
unroll the inner loop to make sure that the indexed access is within 
bounds. Then, when we remove \code{y}, we notice that we don't have to 
set \code{z} as nothing but the \code{MX} macro depends on it, and in 
that case it simply has the value of the data at the previous index 
\code{p}. Again, we replace all occurrences of \code{z} with 
\code{v[p-1]} and pay attention to array bounds.

Finally, the variable \code{p} also needs care when resetting, but that 
is straightforward to do according to the inner loop exit.

The resulting Janus code follows the above description:

\begin{lstlisting}
procedure XXTEA_encipher(u32 data[], u32 key[])
    local u32 delta = 2654435769
    local int n = 4 //size(data)
    local u32 sum = 0
    local u32 e = 0
    local int p = 1
    local int q = 6 + 52/n
    from q = 6 + 52/n loop
        sum += delta
        e += (sum / 4) & 3
        data[0] += ((((data[n-1] / 32) ^ (data[1] * 4)) + ((data[1] / 8) ^ (data[n-1] * 16))) ^ ((sum ^ data[1]) + (key[e] ^ data[n-1])))
        from p = 1 loop
            data[p] += ((((data[p-1] / 32) ^ (data[p+1] * 4)) + ((data[p+1] / 8) ^ (data[p-1] * 16))) ^ ((sum ^ data[p+1]) + (key[(p & 3) ^ (int) e] ^ data[p-1])))
            p += 1
        until p = n-1
        data[n-1] += ((((data[n-2] / 32) ^ (data[0] * 4)) + ((data[0] / 8) ^ (data[n-2] * 16))) ^ ((sum ^ data[0]) + (key[(p & 3) ^ (int) e] ^ data[n-2])))
        p -= (n-2)
        e -= (sum / 4) & 3
        q -= 1
    until q = 0
    delocal int q = 0
    delocal int p = 1
    delocal u32 e = 0
    delocal u32 sum = (6+52 / (u32)n)*delta
    delocal int n = 4 //size(data)
    delocal u32 delta = 2654435769
\end{lstlisting}

\subsection{RC5}

Translating RC5 into Janus was difficult and required extra work in 
designing the reversible code. The encryption function is simple, but 
the key expansion function has grown considerably during translation 
even when partially altered - the last loop has a simplified exit 
condition.

\todo{polish RC5. L is not initialized because of the missing first 
loop. encryption function has wrong api, it should do changes in-place}

\begin{lstlisting}
\end{lstlisting}

\subsection{Salsa20 and Chacha20}
\label{sec:impl:salsa}

In case of Salsa20, we are not taking existing C code or pseudocode and 
translating it into Janus. We are following a precise mathematical 
formulation that is presented in the specification\cite{salsa}. As a 
result, we do not compare our implementation with C code anymore. 
We focus solely on Janus instead.

The first issue appeared with the quarterround function. Initially, a 
misunderstanding of the specification resulted in applying the second 
Bennett's trick like this:

\begin{lstlisting}[language=Janus]
procedure quarterround(u32 seq[4])
	local u32 tmp_seq[4]
	call quarterround_bt(seq, tmp_seq)
	seq[0] <=> tmp_seq[0]
	seq[1] <=> tmp_seq[1]
	seq[2] <=> tmp_seq[2]
	seq[3] <=> tmp_seq[3]
	uncall quarterround_bt(seq, tmp_seq) // 2nd Bennett's trick
	delocal u32 tmp_seq[4]
\end{lstlisting}

Noticing the error, the \code{quarterround} procedure was reimplemented 
to make its computations in-place. Now only one temporary variable is 
required, and that is only due to the feature lacking within the Janus 
language. The suggestion is to implement functions, \ie procedures that 
return a value. Let us consider this extension with an example:

\begin{lstlisting}[language=Janus]
// classic Janus
procedure multiply_proc(int a, int b, int c)
  c += a * b

// Proposed extension
function multiply_func(int a, int b)
  return a * b

// Usage of the procedure, computes result += a * b * c
procedure multiply_three(int a, int b, int c, int result)
  local int tmp = 0
  call multiply_proc(a, b, tmp)
  call multiply_proc(tmp, c, result)
  uncall multiply_proc(a, b, tmp)
  delocal int tmp = 0


// Usage of the function
procedure multiply_three(int a, int b, int c, int result)
  result += call multiply_func(call multiply_func(a, b), c)
\end{lstlisting}

Obviously the procedure \code{multiply\_three} would also be a function, 
but we disregard that for this example.

These functions would be just a syntactic sugar compared to what the 
programmers does with procedures. The extension then would follow these 
steps:

\begin{enumerate}
\item automatically allocate a hidden temporary variable, local to the caller, for storing the returned value
\item add that variable as another parameter
\item replace the \code{return} statement with adding the value to the new parameter (using the \code{+=} operator)
\item add corresponding uncall for clearing that hidden variable in the caller
\end{enumerate}

Note that with these steps followed, the syntactic sugar would in fact 
unroll into this:

\begin{lstlisting}[language=Janus]
// Usage of the procedure, computes result += a * b * c
procedure multiply_three(int a, int b, int c, int result)
  local int hidden_tmp1 = 0
  local int hidden_tmp2 = 0
  call multiply_proc(a, b, hidden_tmp1)
  call multiply_proc(hidden_tmp1, c, hidden_tmp2)
  result += hidden_tmp2
  uncall multiply_proc(hidden_tmp1, c, hidden_tmp2)
  uncall multiply_proc(a, b, tmp)
  delocal int hidden_tmp2 = 0
  delocal int hidden_tmp1 = 0
\end{lstlisting}

This code is not as efficient as the hand-written equivalent above, 
however, in the case of the \code{quarterround} function in Salsa20, 
there would be no performance loss. Consider this piece of code, 
with both the hand-written form and the one with the suggested 
extension:

\begin{lstlisting}[language=Janus]
  // z1 = y1 ^ ((y0 + y3) <<< 7)
  tmp += seq[0] + seq[3]
  call rotate_left_u32(tmp, 7)
  seq[1] ^= tmp
  uncall rotate_left_u32(tmp, 7)
  tmp -= (seq[0] + seq[3])
  
  // z1 = y1 ^ ((y0 + y3) <<< 7)
  seq[1] ^= call rotate_left_u32(seq[0] + seq[3], 7)
\end{lstlisting}

Following the steps above, the automatically unrolled code would be the 
same as the hand-written code. This extension would allow for replacing 
the 22-line procedure with a 5-line function with the same semantics 
and much better readability.


\paragraph{Chacha20}

Chacha20, being only a minor update to Salsa20, does not differ 
dramatically much from its predecessor. The differences consist of 
different operation ordering and are in the \code{doubleround} and the 
\code{quarterround} procedures. 

\section{Lack of leakage and translation}



\chapter{Evaluation}
\label{sec:eval}

In this chapter we attempt to test for the properties discussed in 
section \ref{sec:goals}. These are the goals again:

\begin{enumerate}
\item show lack of state information leakage,
\item exploit the duality of encryption and decryption in a reversible setting,
\item gain practical experience with programming in a reversible language.
\end{enumerate}

We have demonstrated reaching the last goal in previous chapter, where 
we discussed how we implemented some crypto algorithms, showed some 
examples and even gave suggestions for improving the Janus language. At 
the same time, we also reached the second goal, as we implemented only 
encryption functions. The reader can execute our programs which also 
include basic keys and data. Uncalling the encryption function is 
equivalent to calling the decryption function.

The first goal remains and we deal with it here.

\section{Design}

We already mentioned some options for verifying our claim in section 
\ref{sec:verifmet}. The best tool for the job would be Vale, but that 
turned out to be more of a trouble instead of help. There is no doubt 
Vale can be highly useful, but at the time of writing the maturity of 
the project is just not at the required level. Even the installation 
was problematic; we encountered issues that are not usually expected, 
like folder tree structure incompatibility and case sensitivity in file 
naming. There were also other, more common difficulties, like 
dependencies being required at specific version and package management 
issues. When the installation finally succeeded, the problems did not 
disappear. The biggest problems are related to the usability: there is 
very little documentation, there are practically no examples and even 
the source code seems hardly readable\footnote{Subjective assessment, 
the source code for the Vale tool is dense and not commented.}. 
Furthermore, it seems that to take full advantage of the language, the 
user also needs to understand the target language (in our case Dafny) 
and perhaps how the translation is performed. Last but not least, the 
language is extremely complicated and the effort in learning Vale and 
implementing an algorithm in it might not be any lower than just using 
a more classic language and using already established tools and methods 
for debugging and tuning.

Since we cannot use Vale, the next best option is taint tracking in 
combination with automatic cleanup of registers and stack memory. 
Ideally we could use both at the same time, but experiments have shown 
there is a clash between them. The reason is not perfectly clear, but 
suspicion lies with how \term{secretgrind} tracks \term{libc} calls and 
the fact that \term{zerostack} links with \term{musl-libc}. It should 
be possible to remove this problem in a production scenario without too 
much effort. Since \term{secretgrind} also tracks stack, though, we do 
not necessarily require this for the evaluation.

For the evaluation we suggest performing an experiment on selected 
algorithms to approach describing the reality of state leakage. Let us 
describe the experiment in steps:

\begin{description}

\item[Step 1: Translation] We start by translating Janus code into 
C/C++ code. The translation is performed by the Jana interpreter when 
invoked with the \code{-c} option. On its own, the C/C++ code can be 
compiled and executed and performs equivalently to its Janus 
counterpart. There is no input from outside the program, however.

\item[Step 2: Reference] We take a reference implementation of the same 
algorithm and adjust both the reference and the translated code to read 
and process data the same way. The reference should form a baseline for 
our comparison.

\item[Step 3: Taint tracking] We compile both programs the same way and 
input the same data. We compare their execution using 
\term{secretgrind} and evaluate their scores in number of bytes 
potentially leaked.

\item[Step 4: Zerostack substitution] \term{Secretgrind} traces the 
source of the leaks (taints), and so we can examine them. We then 
recompile the programs with \term{zerostack} and re-evaluate the 
situation.

\end{description}

\section{implementations}

\todo{explain edits to translated code and reference chacha implementation}

\section{Experiments}

\subsection{Step 1: Translation}

The code is translated using Jana. There are no manual modifications to 
make the code compile. We use the older version of translation due to 
added complexity in recent Jana versions. Originally Jana used a direct 
translation to C-style arrays, that was substituted by 
\code{std::array} for a short time and then by \code{std::vector}. 
Reason for the replacement of C-style arrays was keeping some record of 
the size of the array. Janus interpreter has a keyword \code{size}, 
which returns the size of the array, since it is always known as it 
does not change. C, on the other hand, uses simple pointers to memory 
and does not track the size of the allocated block\footnote{Not related 
to heap allocations, which do need to track that information 
internally.}. The reason to stick to the original translation is 
simplicity in tracking memory using \term{secretgrind} and the 
immaturity of the recent changes to Jana.

\subsection{Step 2: Reference}

To have something to check our code against, we download reference 
implementations from the Internet. We also add some boilerplate code to 
create executable self-standing programs instead of libraries, and we 
also add a function for reading from a file. This function uses the 
\code{read()} function, since that is simple enough to avoid confusion 
and complexity when tracked by \term{secretgrind}. For the same reason 
we also disable code that prints out the contents of arrays - prior 
experiments have shown that functions like \code{scanf} manipulate and 
taint more memory.

\subsection{Step 3: Taint tracking}

\subsubsection{XXTEA}

XXTEA is the first algorithm for us to examine. While we already talked 
about TEA and XTEA, they are somewhat simpler and perform their 
operations in-place, which limits potential leakage. XXTEA, on the 
other hand, required some work to make the updates in-place. That makes 
it interesting to compare to classic irreversible implementation.

For the testing, we are using the \code{TEA.janus} file, containing all 
three TEA-family algorithms; we only comment out the TEA and XTEA 
invocations. For the reference implementation, we make minor edits to 
the version on Wikipedia\todo{cite or hyperref?}. For input, we load 
both key and data for encryption from a file, that will be marked as 
tainted by \term{secretgrind}. Note that both the key and the data 
block take up 16 bytes of memory, so a non-leaking implementation 
should see exactly 32 bytes in total of tainted memory. Let us look at 
the \term{secretgrind} output for the reference code:

\begin{verbatim}
***(2) (stack)	 range [0xffefffdcc - 0xffefffdcf]	 (4 bytes)	 is tainted
   > (stack) [0xffefffdcc - 0xffefffdcf] (4 bytes): XXTEA-C.c:51:@0xffefffdcc:y
        tainted     at 0x400ABF: xxtea_dec (XXTEA-C.c:62)
                    by 0x400C68: main (XXTEA-C.c:96)

***(1) (stack)	 range [0xffefffdd4 - 0xffefffdd7]	 (4 bytes)	 is tainted
   > (stack) [0xffefffdd4 - 0xffefffdd7] (4 bytes): XXTEA-C.c:51:@0xffefffdd4:z
        tainted     at 0x400A55: xxtea_dec (XXTEA-C.c:61)
                    by 0x400C68: main (XXTEA-C.c:96)

***(1) (stack)	 range [0xffefffe10 - 0xffefffe2f]	 (32 bytes)	 is tainted
   > (stack) [0xffefffe10 - 0xffefffe1f] (16 bytes): XXTEA-C.c:90:@0xffefffe10:key
        tainted     at 0x4F196B0: __read_nocancel (syscall-template.S:81)
                    by 0x400B63: read_data_binary (XXTEA-C.c:77)
                    by 0x400C3E: main (XXTEA-C.c:93)
   > (stack) [0xffefffe20 - 0xffefffe23] (4 bytes): XXTEA-C.c:91:@0xffefffe20:more_data
        tainted     at 0x400AB7: xxtea_dec (XXTEA-C.c:62)
                    by 0x400C68: main (XXTEA-C.c:96)
   > (stack) [0xffefffe24 - 0xffefffe27] (4 bytes): XXTEA-C.c:91:@0xffefffe24:more_data[1]
        tainted     at 0x400A29: xxtea_dec (XXTEA-C.c:59)
                    by 0x400C68: main (XXTEA-C.c:96)
   > (stack) [0xffefffe28 - 0xffefffe2b] (4 bytes): XXTEA-C.c:91:@0xffefffe28:more_data[2]
        tainted     at 0x400A29: xxtea_dec (XXTEA-C.c:59)
                    by 0x400C68: main (XXTEA-C.c:96)
   > (stack) [0xffefffe2c - 0xffefffe2f] (4 bytes): XXTEA-C.c:91:@0xffefffe2c:more_data[3]
        tainted     at 0x400A29: xxtea_dec (XXTEA-C.c:59)
                    by 0x400C68: main (XXTEA-C.c:96)

Total bytes tainted: 40
\end{verbatim}

The printout details three stack ranges. The first two are caused by 
the \code{y} and \code{z} variables, while the last one makes up the 
actual input for the algorithm, that is the key and the data. The leak 
is therefore 8 bytes over the expected 32 bytes.

Because our Janus implementation had to avoid these local erasable 
variables, and thus perform the updates in-place, there are no extra 
leaks:

\begin{verbatim}
***(1) (stack)	 range [0xffefffe20 - 0xffefffe3f]	 (32 bytes)	 is tainted
   > (stack) [0xffefffe20 - 0xffefffe2f] (16 bytes): TEA-translated.cpp:150:@0xffefffe20:key
        tainted     at 0x4F196B0: __read_nocancel (syscall-template.S:81)
                    by 0x4015F6: read_data_binary(unsigned int*, unsigned long, unsigned int*, unsigned long) (TEA-translated.cpp:139)
                    by 0x4016F9: main (TEA-translated.cpp:167)
   > (stack) [0xffefffe30 - 0xffefffe33] (4 bytes): TEA-translated.cpp:152:@0xffefffe30:more_data
        tainted     at 0x401450: XXTEA_encipher_reverse(unsigned int*, unsigned int*) (TEA-translated.cpp:117)
                    by 0x40171F: main (TEA-translated.cpp:180)
   > (stack) [0xffefffe34 - 0xffefffe37] (4 bytes): TEA-translated.cpp:152:@0xffefffe34:more_data[1]
        tainted     at 0x40137F: XXTEA_encipher_reverse(unsigned int*, unsigned int*) (TEA-translated.cpp:114)
                    by 0x40171F: main (TEA-translated.cpp:180)
   > (stack) [0xffefffe38 - 0xffefffe3b] (4 bytes): TEA-translated.cpp:152:@0xffefffe38:more_data[2]
        tainted     at 0x40137F: XXTEA_encipher_reverse(unsigned int*, unsigned int*) (TEA-translated.cpp:114)
                    by 0x40171F: main (TEA-translated.cpp:180)
   > (stack) [0xffefffe3c - 0xffefffe3f] (4 bytes): TEA-translated.cpp:152:@0xffefffe3c:more_data[3]
        tainted     at 0x40124E: XXTEA_encipher_reverse(unsigned int*, unsigned int*) (TEA-translated.cpp:110)
                    by 0x40171F: main (TEA-translated.cpp:180)

Total bytes tainted: 32
\end{verbatim}

It has to be pointed out that the leakage-free result could be achieved 
the same way originally. The difference is that the opposite is not 
true: reversible programming does not allow the leaking version. Still 
this is a fairly simple algorithm, so let us move on.

\subsubsection{Chacha20}

\todo{missing description here, posting just the results for now.}

Expected bytes tainted: 64 (16*4)

%In the reference version, there are 7 stack ranges in total with far 
%too many individual locations to show them. We only show an excerpt 
%from the output with the total number of bytes tainted at the bottom:

%\begin{verbatim}
%log_chacha-ref.txt:11: ***(1) (stack)	 range [0xffefffbb0 - 0xffefffbef]	 (64 bytes)	 is tainted
%log_chacha-ref.txt:90: ***(2) (stack)	 range [0xffefffc00 - 0xffefffc03]	 (4 bytes)	 is tainted
%log_chacha-ref.txt:96: ***(1) (stack)	 range [0xffefffc30 - 0xffefffc77]	 (72 bytes)	 is tainted
%log_chacha-ref.txt:442: ***(2) (stack)	 range [0xffefffc90 - 0xffefffc93]	 (4 bytes)	 is tainted
%log_chacha-ref.txt:460: ***(1) (stack)	 range [0xffefffce0 - 0xffefffcff]	 (32 bytes)	 is tainted
%log_chacha-ref.txt:486: ***(1) (stack)	 range [0xffefffd20 - 0xffefffd2f]	 (16 bytes)	 is tainted
%log_chacha-ref.txt:492: ***(1) (stack)	 range [0xffefffd40 - 0xffefffdff]	 (192 bytes)	 is tainted
%Total bytes tainted: 384
%\end{verbatim}

In the reference version, there is one stack range for all the data. We 
only show an excerpt from the output with the total number of bytes 
tainted at the bottom:

\begin{verbatim}
log_chacha-ref-nokey.txt:11: ***(1) (stack)	 range [0xffefffd40 - 0xffefffdff]	 (192 bytes)	 is tainted
Total bytes tainted: 192
\end{verbatim}

Our Janus-to-C translated version is more modest: only the expected 64 
bytes are marked as tainted. For some reason, \term{secretgrind} split 
the data array into 3 sections, but on inspection they do reside right 
after each other in memory.

\begin{verbatim}
***(1) (stack)	 range [0xffefffdc0 - 0xffefffdff]	 (64 bytes)	 is tainted
   > (stack) [0xffefffdc0 - 0xffefffdc3] (4 bytes): Chacha20.janus.3.cpp:702:@0xffefffdc0:seq
        tainted     at 0x403743: Chacha20_encrypt_forward(unsigned int*, unsigned int*) (Chacha20.janus.3.cpp:637)
                    by 0x403C31: main (Chacha20.janus.3.cpp:726)
   > (stack) [0xffefffdc4 - 0xffefffdc7] (4 bytes): Chacha20.janus.3.cpp:702:@0xffefffdc4:seq[1]
        tainted     at 0x403743: Chacha20_encrypt_forward(unsigned int*, unsigned int*) (Chacha20.janus.3.cpp:637)
                    by 0x403C03: main (Chacha20.janus.3.cpp:723)
   > (stack) [0xffefffdc8 - 0xffefffdff] (56 bytes): Chacha20.janus.3.cpp:702:@0xffefffdc0:seq
        tainted     at 0x4F196B0: __read_nocancel (syscall-template.S:81)
                    by 0x403A05: read_data_binary(unsigned int*, unsigned long, unsigned int*, unsigned long) (Chacha20.janus.3.cpp:686)
                    by 0x403B78: main (Chacha20.janus.3.cpp:711)

Total bytes tainted: 64
\end{verbatim}



\subsection{Step 4: Zerostack substitution}

\todo{Since I can't get zerostack and secretgrind working together, I 
want to show how zerostack zeroes out memory (e.g. the instructions 
injected, their location and what it erases) and compare it to the 
non-erasing binary that we run under secretgrind. I can manually show 
that zerostack would erase those leaking memory locations.}

\todo{what about memset\_s? could I use it with secretgrind? it would 
also be simpler to add to Jana's output}

\chapter{Reflections}

Evaluation of our solution in a broader context, usability in practice 
and viability of real-world implementation

\todo{add what's required for usability: random number generators, nonce generators}

\chapter{Related Work}

obvious

\chapter{Conclusion}

Discussion of results.

\section{Contributions}

These are the contributions from work on this thesis:

\begin{itemize}

\item We have shown reversible computing has other interesting and 
valuable uses other than power consumption savings and quantum 
computing applications; these are better code security and lower 
development costs for bidirectional algorithms.

\item We have suggested new enhancements and improvements to Janus or 
its interpreter Jana. Some of these were implemented alongside the 
research. We have also found and helped fixing several bugs in Jana. 16 
is currently the number of reported issues with Jana, more issues were 
discussed in person.

\item We have published our findings in our paper\cite{revcry-paper}, which 
has been accepted to the Reversible Computation Workshop 2018. We have 
also presented our research at the \term{Öresund Security Day Spring 
2018} conference.

\item All the work is freely accessible on 
Github\cite{revcry-github}. This includes the algorithms, 
supporting files like other source codes, binaries and listings, this 
thesis source files and the wiki resources.

\item \todo{what else?}

\end{itemize}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% BIBLIOGRAPHY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\renewcommand{\sc}[1]{\textsc{#1}}
\nocite{*}
\bibliographystyle{acm}
\bibliography{bibliography}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Appendix
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\cleardoublepage
\appendix

% Updates section names to remove . (e.g. a section is named A1 instead of A.1)
\renewcommand{\thesection}{\thechapter\arabic{section}}

\chapter{The extra}


% To make sure that the backside print of the dissertation is a white page
\newpage ~
\thispagestyle{empty}



\end{document}
